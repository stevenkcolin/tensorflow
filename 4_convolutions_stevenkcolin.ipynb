{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_convolutions-stevenkcolin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenkcolin/tensorflow/blob/master/4_convolutions_stevenkcolin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4embtkV0pNxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Deep Learning\n",
        "=============\n",
        "\n",
        "Assignment 4\n",
        "------------\n",
        "\n",
        "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
        "\n",
        "The goal of this assignment is make the neural network convolutional."
      ]
    },
    {
      "metadata": {
        "id": "MIUvG1R4HjX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b49d7a17-a91c-4a4a-9cb3-7c27a3351ff2"
      },
      "cell_type": "code",
      "source": [
        "!ls -lt"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 924432\n",
            "-rw-r--r--  1 root   root 690800441 Jan 29 05:57 notMNIST.pickle\n",
            "drwxrwxr-x 12 133040 5000      4096 Jan 29 05:57 notMNIST_small\n",
            "drwxrwxr-x 12 133040 5000      4096 Jan 29 05:56 notMNIST_large\n",
            "-rw-r--r--  1 root   root   8458043 Jan 29 05:49 notMNIST_small.tar.gz\n",
            "-rw-r--r--  1 root   root 247336696 Jan 29 05:49 notMNIST_large.tar.gz\n",
            "drwxr-xr-x  1 root   root      4096 Jan  8 17:15 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tm2CQN_Cpwj0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from six.moves import cPickle as pickle\n",
        "from six.moves import range"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3-cj1bpmuxc",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "58da8675-9c7a-45ee-cf38-62b1c7cc34e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "pickle_file = 'notMNIST.pickle'\n",
        "\n",
        "with open(pickle_file, 'rb') as f:\n",
        "  save = pickle.load(f)\n",
        "  train_dataset = save['train_dataset']\n",
        "  train_labels = save['train_labels']\n",
        "  valid_dataset = save['valid_dataset']\n",
        "  valid_labels = save['valid_labels']\n",
        "  test_dataset = save['test_dataset']\n",
        "  test_labels = save['test_labels']\n",
        "  del save  # hint to help gc free up memory\n",
        "  print('Training set', train_dataset.shape, train_labels.shape)\n",
        "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "  print('Test set', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (200000, 28, 28) (200000,)\n",
            "Validation set (10000, 28, 28) (10000,)\n",
            "Test set (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L7aHrm6nGDMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reformat into a TensorFlow-friendly shape:\n",
        "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
        "- labels as float 1-hot encodings."
      ]
    },
    {
      "metadata": {
        "id": "IRSyYiIIGIzS",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "729b1ab9-f6c5-4c57-ef5e-3f6a37ae0b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "image_size = 28\n",
        "num_labels = 10\n",
        "num_channels = 1 # grayscale\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def reformat(dataset, labels):\n",
        "  dataset = dataset.reshape(\n",
        "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
        "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
        "  return dataset, labels\n",
        "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
        "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
        "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
        "print('Training set', train_dataset.shape, train_labels.shape)\n",
        "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "print('Test set', test_dataset.shape, test_labels.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (200000, 28, 28, 1) (200000, 10)\n",
            "Validation set (10000, 28, 28, 1) (10000, 10)\n",
            "Test set (10000, 28, 28, 1) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AgQDIREv02p1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(predictions, labels):\n",
        "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
        "          / predictions.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rhgjmROXu2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
      ]
    },
    {
      "metadata": {
        "id": "rcPypa1jpREs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 基本模型是 \n",
        "\n",
        "$$\n",
        "Model = conv_1 + relu_1 + conv_2 + relu_2 + FC + Classifier\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "IZYv70SvvOan",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "patch_size = 5\n",
        "depth = 16\n",
        "num_hidden = 64\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data.\n",
        "  tf_train_dataset = tf.placeholder(\n",
        "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_valid_dataset = tf.constant(valid_dataset)\n",
        "  tf_test_dataset = tf.constant(test_dataset)\n",
        "  \n",
        "  # Variables.\n",
        "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
        "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
        "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
        "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
        "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
        "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
        "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
        "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
        "      [num_hidden, num_labels], stddev=0.1))\n",
        "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
        "  \n",
        "  # Model.\n",
        "  # Model = conv1 + relu1 +  conv2 + relu2 + FC + classifier\n",
        "  def model(data):\n",
        "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
        "    hidden = tf.nn.relu(conv + layer1_biases)\n",
        "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
        "    hidden = tf.nn.relu(conv + layer2_biases)\n",
        "    shape = hidden.get_shape().as_list()\n",
        "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
        "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
        "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
        "  \n",
        "  # Training computation.\n",
        "  logits = model(tf_train_dataset)\n",
        "  loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
        "    \n",
        "  # Optimizer.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
        "  \n",
        "  # Predictions for the training, validation, and test data.\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
        "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "noKFb2UovVFR",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "8ab14f59-c087-46fd-c0af-426bb55a6d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "num_steps = 1001\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  print('Initialized')\n",
        "  for step in range(num_steps):\n",
        "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "    _, l, predictions = session.run(\n",
        "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "    if (step % 50 == 0):\n",
        "      print('Minibatch loss at step %d: %f' % (step, l))\n",
        "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
        "      print('Validation accuracy: %.1f%%' % accuracy(\n",
        "        valid_prediction.eval(), valid_labels))\n",
        "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Minibatch loss at step 0: 2.943997\n",
            "Minibatch accuracy: 6.2%\n",
            "Validation accuracy: 10.0%\n",
            "Minibatch loss at step 50: 2.193009\n",
            "Minibatch accuracy: 12.5%\n",
            "Validation accuracy: 47.7%\n",
            "Minibatch loss at step 100: 0.608371\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 67.6%\n",
            "Minibatch loss at step 150: 1.230256\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 72.7%\n",
            "Minibatch loss at step 200: 0.687688\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 74.0%\n",
            "Minibatch loss at step 250: 0.690797\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 78.3%\n",
            "Minibatch loss at step 300: 1.050910\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 78.8%\n",
            "Minibatch loss at step 350: 1.017363\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 78.8%\n",
            "Minibatch loss at step 400: 0.335318\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 79.1%\n",
            "Minibatch loss at step 450: 1.014865\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 80.0%\n",
            "Minibatch loss at step 500: 0.428346\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 80.6%\n",
            "Minibatch loss at step 550: 0.786218\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.5%\n",
            "Minibatch loss at step 600: 0.680063\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 81.6%\n",
            "Minibatch loss at step 650: 0.642961\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.6%\n",
            "Minibatch loss at step 700: 0.754934\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 80.5%\n",
            "Minibatch loss at step 750: 0.538781\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 80.8%\n",
            "Minibatch loss at step 800: 0.893254\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.5%\n",
            "Minibatch loss at step 850: 0.408738\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 83.0%\n",
            "Minibatch loss at step 900: 1.363880\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 82.4%\n",
            "Minibatch loss at step 950: 0.672380\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.9%\n",
            "Minibatch loss at step 1000: 0.590857\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.0%\n",
            "Test accuracy: 89.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KedKkn4EutIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Problem 1\n",
        "---------\n",
        "\n",
        "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "4ONhEBgepjMu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 基本模型是\n",
        "$$\n",
        "Model = conv_1 + relu_1 + pool_1 + conv_2 + relu_2 + pool_2 + FC + classifier\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "b67vl1GojqfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "patch_size = 5\n",
        "depth = 16\n",
        "num_hidden = 64\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data.\n",
        "  tf_train_dataset = tf.placeholder(\n",
        "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_valid_dataset = tf.constant(valid_dataset)\n",
        "  tf_test_dataset = tf.constant(test_dataset)\n",
        "  \n",
        "  # Variables.\n",
        "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
        "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
        "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
        "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
        "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
        "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
        "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
        "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
        "      [num_hidden, num_labels], stddev=0.1))\n",
        "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
        "  \n",
        "  # Model.\n",
        "  # Model = conv1 + relu1 + pool1 + conv2 + relu2 + pool2 + FC + classifier\n",
        "  def model(data):\n",
        "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
        "    bias1 = tf.nn.relu(conv1 + layer1_biases)\n",
        "    pool1 = tf.nn.max_pool(bias1, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
        "    conv2 = tf.nn.conv2d(pool1, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
        "    bias2 = tf.nn.relu(conv2 + layer2_biases)\n",
        "    pool2 = tf.nn.max_pool(bias2, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
        "    shape = pool2.get_shape().as_list()\n",
        "    reshape = tf.reshape(pool2, [shape[0], shape[1] * shape[2] * shape[3]])\n",
        "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
        "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
        "  \n",
        "  # Training computation.\n",
        "  logits = model(tf_train_dataset)\n",
        "  loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
        "    \n",
        "  # Optimizer.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
        "  \n",
        "  # Predictions for the training, validation, and test data.\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
        "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "457RbSrMjzRg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        },
        "outputId": "b5369a85-496b-4060-f71a-4ffb99d7c9a1"
      },
      "cell_type": "code",
      "source": [
        "num_steps = 1001\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  tf.initialize_all_variables().run()\n",
        "  print('Initialized')\n",
        "  for step in range(num_steps):\n",
        "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "    _, l, predictions = session.run(\n",
        "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "    if (step % 50 == 0):\n",
        "      print('Minibatch loss at step %d: %f' % (step, l))\n",
        "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
        "      print('Validation accuracy: %.1f%%' % accuracy(\n",
        "        valid_prediction.eval(), valid_labels))\n",
        "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Minibatch loss at step 0: 2.377371\n",
            "Minibatch accuracy: 18.8%\n",
            "Validation accuracy: 10.0%\n",
            "Minibatch loss at step 50: 2.336373\n",
            "Minibatch accuracy: 18.8%\n",
            "Validation accuracy: 19.3%\n",
            "Minibatch loss at step 100: 1.029919\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 50.7%\n",
            "Minibatch loss at step 150: 1.192179\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 62.9%\n",
            "Minibatch loss at step 200: 0.812730\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 74.9%\n",
            "Minibatch loss at step 250: 0.729635\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 76.5%\n",
            "Minibatch loss at step 300: 1.339047\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 75.6%\n",
            "Minibatch loss at step 350: 0.894602\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 80.4%\n",
            "Minibatch loss at step 400: 0.333972\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 80.2%\n",
            "Minibatch loss at step 450: 1.107833\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 80.5%\n",
            "Minibatch loss at step 500: 0.352070\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 80.8%\n",
            "Minibatch loss at step 550: 1.123577\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.2%\n",
            "Minibatch loss at step 600: 0.624851\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.0%\n",
            "Minibatch loss at step 650: 0.744697\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.1%\n",
            "Minibatch loss at step 700: 0.750341\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.7%\n",
            "Minibatch loss at step 750: 0.534885\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.3%\n",
            "Minibatch loss at step 800: 0.759235\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.2%\n",
            "Minibatch loss at step 850: 0.583230\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.8%\n",
            "Minibatch loss at step 900: 1.050115\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.2%\n",
            "Minibatch loss at step 950: 0.580369\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 1000: 0.491398\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.1%\n",
            "Test accuracy: 90.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "klf21gpbAgb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Problem 2\n",
        "---------\n",
        "\n",
        "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "DOZdNMbZj6Lt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "patch_size = 5\n",
        "depth = 16\n",
        "num_hidden = 64\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data.\n",
        "  tf_train_dataset = tf.placeholder(\n",
        "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_valid_dataset = tf.constant(valid_dataset)\n",
        "  tf_test_dataset = tf.constant(test_dataset)\n",
        "  \n",
        "  # Variables.\n",
        "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
        "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
        "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
        "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
        "  size3 = ((image_size - patch_size + 1) // 2 - patch_size + 1) // 2\n",
        "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
        "      [size3 * size3 * depth, num_hidden], stddev=0.1))\n",
        "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
        "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
        "      [num_hidden, num_labels], stddev=0.1))\n",
        "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
        "  \n",
        "  # Model.\n",
        "  def model(data):\n",
        "    # C1 input 28 x 28\n",
        "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='VALID')\n",
        "    bias1 = tf.nn.relu(conv1 + layer1_biases)\n",
        "    # S2 input 24 x 24\n",
        "    pool2 = tf.nn.avg_pool(bias1, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
        "    # C3 input 12 x 12\n",
        "    conv3 = tf.nn.conv2d(pool2, layer2_weights, [1, 1, 1, 1], padding='VALID')\n",
        "    bias3 = tf.nn.relu(conv3 + layer2_biases)\n",
        "    # S4 input 8 x 8\n",
        "    pool4 = tf.nn.avg_pool(bias3, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
        "    # F6 input 4 x 4\n",
        "    shape = pool4.get_shape().as_list()\n",
        "    reshape = tf.reshape(pool4, [shape[0], shape[1] * shape[2] * shape[3]])\n",
        "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
        "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
        "  \n",
        "  # Training computation.\n",
        "  logits = model(tf_train_dataset)\n",
        "  loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
        "    \n",
        "  # Optimizer.\n",
        "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
        "  \n",
        "  # Predictions for the training, validation, and test data.\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
        "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t32-q7JwkY2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20502
        },
        "outputId": "a0b8c985-2852-4c3b-f74b-6332235cd631"
      },
      "cell_type": "code",
      "source": [
        "num_steps = 20001\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  tf.initialize_all_variables().run()\n",
        "  print('Initialized')\n",
        "  for step in range(num_steps):\n",
        "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "    _, l, predictions = session.run(\n",
        "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "    if (step % 50 == 0):\n",
        "      print('Minibatch loss at step %d: %f' % (step, l))\n",
        "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
        "      print('Validation accuracy: %.1f%%' % accuracy(\n",
        "        valid_prediction.eval(), valid_labels))\n",
        "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Minibatch loss at step 0: 2.967762\n",
            "Minibatch accuracy: 0.0%\n",
            "Validation accuracy: 10.0%\n",
            "Minibatch loss at step 50: 2.005604\n",
            "Minibatch accuracy: 25.0%\n",
            "Validation accuracy: 52.2%\n",
            "Minibatch loss at step 100: 0.874942\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 58.6%\n",
            "Minibatch loss at step 150: 1.273653\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 65.1%\n",
            "Minibatch loss at step 200: 0.861201\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 70.3%\n",
            "Minibatch loss at step 250: 0.834041\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 75.1%\n",
            "Minibatch loss at step 300: 1.459347\n",
            "Minibatch accuracy: 56.2%\n",
            "Validation accuracy: 75.5%\n",
            "Minibatch loss at step 350: 1.072278\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 78.0%\n",
            "Minibatch loss at step 400: 0.318564\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 77.3%\n",
            "Minibatch loss at step 450: 1.050640\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 78.2%\n",
            "Minibatch loss at step 500: 0.479967\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 78.3%\n",
            "Minibatch loss at step 550: 0.772555\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 79.1%\n",
            "Minibatch loss at step 600: 0.824356\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 80.1%\n",
            "Minibatch loss at step 650: 0.993188\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 80.4%\n",
            "Minibatch loss at step 700: 0.664315\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 79.8%\n",
            "Minibatch loss at step 750: 0.757420\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 80.6%\n",
            "Minibatch loss at step 800: 1.028573\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 80.7%\n",
            "Minibatch loss at step 850: 0.596780\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.5%\n",
            "Minibatch loss at step 900: 1.282395\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 80.9%\n",
            "Minibatch loss at step 950: 0.696703\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.4%\n",
            "Minibatch loss at step 1000: 0.538025\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.6%\n",
            "Minibatch loss at step 1050: 0.149293\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 82.0%\n",
            "Minibatch loss at step 1100: 0.531585\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.8%\n",
            "Minibatch loss at step 1150: 0.407867\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 82.7%\n",
            "Minibatch loss at step 1200: 1.090386\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 82.2%\n",
            "Minibatch loss at step 1250: 0.476261\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.4%\n",
            "Minibatch loss at step 1300: 0.259351\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 82.3%\n",
            "Minibatch loss at step 1350: 0.359270\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 82.6%\n",
            "Minibatch loss at step 1400: 0.811023\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.0%\n",
            "Minibatch loss at step 1450: 0.503695\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 83.3%\n",
            "Minibatch loss at step 1500: 0.747620\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 83.2%\n",
            "Minibatch loss at step 1550: 0.431266\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 82.8%\n",
            "Minibatch loss at step 1600: 0.702977\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.9%\n",
            "Minibatch loss at step 1650: 0.036616\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 83.5%\n",
            "Minibatch loss at step 1700: 0.422767\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 83.8%\n",
            "Minibatch loss at step 1750: 0.490531\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.8%\n",
            "Minibatch loss at step 1800: 0.947865\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.9%\n",
            "Minibatch loss at step 1850: 0.344788\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.3%\n",
            "Minibatch loss at step 1900: 0.031407\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 82.9%\n",
            "Minibatch loss at step 1950: 0.158962\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 84.1%\n",
            "Minibatch loss at step 2000: 0.543844\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 2050: 0.345829\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 84.6%\n",
            "Minibatch loss at step 2100: 1.039287\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 2150: 0.888449\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 2200: 0.090616\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 84.1%\n",
            "Minibatch loss at step 2250: 0.315256\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 2300: 0.453881\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 2350: 0.318511\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 2400: 0.816924\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 2450: 0.603620\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 2500: 0.924206\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 2550: 0.258780\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 2600: 0.058684\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 2650: 0.553156\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 2700: 0.356364\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.6%\n",
            "Minibatch loss at step 2750: 0.119650\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 2800: 0.360974\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.2%\n",
            "Minibatch loss at step 2850: 0.198097\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 2900: 0.142866\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 85.4%\n",
            "Minibatch loss at step 2950: 0.555321\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.4%\n",
            "Minibatch loss at step 3000: 0.641246\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 3050: 0.086818\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 3100: 0.838985\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 3150: 0.580713\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.9%\n",
            "Minibatch loss at step 3200: 0.680383\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 3250: 0.544378\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 3300: 0.825023\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 3350: 0.494821\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 3400: 0.462310\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 3450: 0.334435\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 3500: 0.755561\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 3550: 0.172405\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.2%\n",
            "Minibatch loss at step 3600: 0.439856\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 3650: 0.356884\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.5%\n",
            "Minibatch loss at step 3700: 0.504760\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.2%\n",
            "Minibatch loss at step 3750: 0.533546\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.5%\n",
            "Minibatch loss at step 3800: 0.514323\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 3850: 0.598881\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.2%\n",
            "Minibatch loss at step 3900: 0.530081\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 3950: 0.440901\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.7%\n",
            "Minibatch loss at step 4000: 0.459687\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.7%\n",
            "Minibatch loss at step 4050: 0.293772\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.5%\n",
            "Minibatch loss at step 4100: 0.218483\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.8%\n",
            "Minibatch loss at step 4150: 0.445456\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.8%\n",
            "Minibatch loss at step 4200: 0.319577\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4250: 0.018904\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.8%\n",
            "Minibatch loss at step 4300: 0.078625\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.4%\n",
            "Minibatch loss at step 4350: 0.316898\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.8%\n",
            "Minibatch loss at step 4400: 0.094517\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.6%\n",
            "Minibatch loss at step 4450: 0.340695\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.6%\n",
            "Minibatch loss at step 4500: 0.359302\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.6%\n",
            "Minibatch loss at step 4550: 0.855006\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 4600: 0.620471\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.7%\n",
            "Minibatch loss at step 4650: 0.512992\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.6%\n",
            "Minibatch loss at step 4700: 0.479388\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.7%\n",
            "Minibatch loss at step 4750: 0.317194\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.9%\n",
            "Minibatch loss at step 4800: 0.269198\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 4850: 0.519953\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.8%\n",
            "Minibatch loss at step 4900: 0.658591\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.2%\n",
            "Minibatch loss at step 4950: 0.957356\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.1%\n",
            "Minibatch loss at step 5000: 0.043767\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.1%\n",
            "Minibatch loss at step 5050: 0.168167\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 5100: 0.153760\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 5150: 0.416218\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.1%\n",
            "Minibatch loss at step 5200: 0.262905\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.7%\n",
            "Minibatch loss at step 5250: 0.151061\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.6%\n",
            "Minibatch loss at step 5300: 0.908968\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 5350: 0.802313\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.2%\n",
            "Minibatch loss at step 5400: 0.189584\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 5450: 0.157020\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.2%\n",
            "Minibatch loss at step 5500: 0.644119\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.6%\n",
            "Minibatch loss at step 5550: 0.280915\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 5600: 0.657985\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.4%\n",
            "Minibatch loss at step 5650: 0.244415\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 5700: 0.049463\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.6%\n",
            "Minibatch loss at step 5750: 0.142476\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 5800: 0.214574\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 5850: 0.359690\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 5900: 0.638790\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 5950: 0.211595\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 6000: 0.586787\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.9%\n",
            "Minibatch loss at step 6050: 0.138130\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 6100: 0.221615\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 6150: 0.444229\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.6%\n",
            "Minibatch loss at step 6200: 0.357070\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 6250: 0.754399\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 87.9%\n",
            "Minibatch loss at step 6300: 0.478225\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.2%\n",
            "Minibatch loss at step 6350: 0.510551\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.4%\n",
            "Minibatch loss at step 6400: 0.716090\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.0%\n",
            "Minibatch loss at step 6450: 0.301741\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 6500: 1.040477\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 87.4%\n",
            "Minibatch loss at step 6550: 0.056688\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 6600: 0.356792\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.1%\n",
            "Minibatch loss at step 6650: 0.404228\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 87.4%\n",
            "Minibatch loss at step 6700: 0.673032\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 6750: 0.451086\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.8%\n",
            "Minibatch loss at step 6800: 0.337847\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.8%\n",
            "Minibatch loss at step 6850: 0.409955\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 87.9%\n",
            "Minibatch loss at step 6900: 0.312881\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 6950: 0.435810\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.8%\n",
            "Minibatch loss at step 7000: 1.144924\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 7050: 0.851890\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 7100: 0.201734\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 87.6%\n",
            "Minibatch loss at step 7150: 0.176161\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.8%\n",
            "Minibatch loss at step 7200: 0.526047\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.3%\n",
            "Minibatch loss at step 7250: 0.359855\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 7300: 0.152317\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 7350: 0.320472\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.5%\n",
            "Minibatch loss at step 7400: 0.416797\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 7450: 0.475903\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 7500: 0.187122\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 7550: 0.632861\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 7600: 0.131935\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.9%\n",
            "Minibatch loss at step 7650: 0.081784\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 7700: 0.197295\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 7750: 0.312034\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 87.9%\n",
            "Minibatch loss at step 7800: 0.466225\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 7850: 0.259078\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 7900: 0.385575\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 7950: 0.167901\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 8000: 0.645973\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 8050: 0.148755\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 8100: 0.048243\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 8150: 0.529249\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 8200: 0.058019\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 8250: 0.583067\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.9%\n",
            "Minibatch loss at step 8300: 0.322459\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 8350: 0.502688\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 8400: 0.631409\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 8450: 0.470321\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 8500: 0.367417\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 8550: 0.173247\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 8600: 0.475928\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 8650: 1.030513\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 8700: 0.071890\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 8750: 1.321156\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 8800: 0.494091\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 8850: 1.179314\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 8900: 0.356666\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 8950: 0.827326\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 9000: 0.248407\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 9050: 0.993176\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 9100: 0.145908\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 9150: 0.530429\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 9200: 0.508552\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 9250: 0.360113\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 9300: 0.221558\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 9350: 0.543491\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 9400: 0.165039\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 9450: 0.111568\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 9500: 0.284693\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 9550: 0.276975\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 9600: 0.363026\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 9650: 0.344167\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 87.7%\n",
            "Minibatch loss at step 9700: 0.609894\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 9750: 0.470009\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 9800: 0.186574\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 9850: 0.491383\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 9900: 0.442085\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 9950: 0.819782\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 10000: 0.575930\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 10050: 0.363640\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 10100: 0.828638\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 10150: 0.515851\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 10200: 0.299358\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 10250: 0.468117\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.1%\n",
            "Minibatch loss at step 10300: 0.094280\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 10350: 0.044613\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.0%\n",
            "Minibatch loss at step 10400: 0.471835\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 10450: 0.167820\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 10500: 0.286145\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 10550: 0.010872\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 10600: 0.719326\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 10650: 0.044965\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 10700: 0.348369\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 10750: 0.292773\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 10800: 0.382213\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 10850: 0.052356\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 10900: 0.293222\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 10950: 0.298716\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 11000: 1.227865\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 11050: 0.344694\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 11100: 0.910267\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11150: 0.340141\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11200: 0.490523\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 11250: 0.752173\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 11300: 0.058974\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11350: 0.403764\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11400: 0.670348\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 11450: 0.292022\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.2%\n",
            "Minibatch loss at step 11500: 0.748760\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 11550: 0.436894\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 11600: 0.025857\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 11650: 0.176120\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 11700: 0.269099\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 11750: 0.347176\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11800: 0.532238\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 11850: 0.266034\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 11900: 0.410717\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 11950: 0.241501\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 12000: 0.420225\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12050: 0.251330\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 12100: 0.726601\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 12150: 0.316922\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.3%\n",
            "Minibatch loss at step 12200: 0.740343\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 12250: 0.184082\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 12300: 0.444735\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 12350: 0.430364\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12400: 0.352903\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 12450: 0.516505\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 12500: 0.028938\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 12550: 0.062654\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.4%\n",
            "Minibatch loss at step 12600: 0.418239\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12650: 0.265936\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 12700: 0.464914\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 12750: 0.459578\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12800: 0.201933\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12850: 0.279380\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12900: 0.036539\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 12950: 0.307119\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13000: 0.422236\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 13050: 0.139081\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13100: 0.249690\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13150: 0.300328\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 13200: 0.135468\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 13250: 0.823560\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 13300: 0.315829\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 13350: 0.203179\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13400: 0.470308\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 13450: 0.582936\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 13500: 0.115065\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13550: 0.106347\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 13600: 0.111967\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 13650: 0.303608\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 13700: 0.256912\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 13750: 0.142374\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 13800: 0.444268\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 13850: 0.118114\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 13900: 0.174963\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 13950: 0.531748\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.6%\n",
            "Minibatch loss at step 14000: 0.453992\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14050: 0.701096\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 14100: 0.064571\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 14150: 0.159519\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14200: 0.246454\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14250: 0.283775\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 14300: 0.093017\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 14350: 0.436016\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14400: 0.159310\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 14450: 0.105200\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14500: 0.096721\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14550: 0.544274\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 14600: 0.012327\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 14650: 0.792128\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 14700: 0.284159\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 14750: 0.756450\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 14800: 0.440758\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 14850: 0.255615\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 14900: 0.622352\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 14950: 0.095307\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15000: 0.377122\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 15050: 0.341951\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 15100: 0.424573\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 15150: 0.157586\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 15200: 0.565565\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 15250: 0.055287\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15300: 0.087166\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15350: 0.443746\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 15400: 0.379654\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 15450: 0.215593\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 15500: 0.491478\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 15550: 0.193385\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15600: 0.164536\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.5%\n",
            "Minibatch loss at step 15650: 0.594870\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15700: 0.298177\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 15750: 0.098965\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 15800: 0.822024\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 15850: 0.842237\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15900: 0.084725\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 15950: 0.682961\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 16000: 0.545600\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16050: 0.120602\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 16100: 0.342160\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16150: 0.088740\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 16200: 0.674401\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16250: 0.243603\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 16300: 0.084345\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 16350: 0.459097\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 16400: 0.279290\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 16450: 1.076359\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 88.8%\n",
            "Minibatch loss at step 16500: 0.540850\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 16550: 0.050590\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 16600: 0.650628\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16650: 0.100217\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16700: 0.431567\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 16750: 0.822293\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 16800: 0.158894\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 16850: 0.252858\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 16900: 0.078345\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 16950: 0.316374\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 17000: 0.307084\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.0%\n",
            "Minibatch loss at step 17050: 0.105105\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 88.9%\n",
            "Minibatch loss at step 17100: 0.486280\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 17150: 0.009339\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 17200: 0.336388\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 17250: 0.173762\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 17300: 0.549183\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 17350: 0.110356\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 17400: 0.036880\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 17450: 0.036278\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 17500: 0.771624\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 17550: 0.004636\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 17600: 0.694908\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 17650: 0.273576\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 17700: 0.395342\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 17750: 0.271639\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 17800: 0.174644\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 17850: 0.464879\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 17900: 0.147529\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 17950: 0.559358\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 18000: 0.496266\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 18050: 0.541626\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 18100: 0.204299\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 18150: 0.567681\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 18200: 0.508111\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 18250: 0.443748\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18300: 0.323893\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18350: 0.478301\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 18400: 0.159734\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18450: 0.383343\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 18500: 0.187270\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18550: 0.099229\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18600: 0.104018\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18650: 0.094425\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 18700: 0.615577\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 18750: 0.059991\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 18800: 0.539337\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 18850: 0.207512\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 18900: 0.311553\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 18950: 0.409623\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 19000: 0.201809\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 19050: 0.185497\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19100: 0.367776\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 88.7%\n",
            "Minibatch loss at step 19150: 0.201973\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 19200: 0.280901\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19250: 0.324684\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.8%\n",
            "Minibatch loss at step 19300: 0.453072\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 19350: 0.560991\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 19400: 0.179375\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.2%\n",
            "Minibatch loss at step 19450: 0.562925\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19500: 0.357254\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19550: 0.977601\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 89.5%\n",
            "Minibatch loss at step 19600: 0.023651\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 89.3%\n",
            "Minibatch loss at step 19650: 0.309923\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19700: 0.398459\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Minibatch loss at step 19750: 0.625049\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 19800: 0.356670\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.7%\n",
            "Minibatch loss at step 19850: 0.218681\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.1%\n",
            "Minibatch loss at step 19900: 0.304568\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.6%\n",
            "Minibatch loss at step 19950: 0.340828\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 89.8%\n",
            "Minibatch loss at step 20000: 0.147241\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 89.4%\n",
            "Test accuracy: 94.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41hvPHm7kftg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "patch_size = 5\n",
        "depth = 16\n",
        "num_hidden = 64\n",
        "beta_regul = 1e-3\n",
        "drop_out = 0.5\n",
        "\n",
        "graph = tf.Graph()\n",
        "\n",
        "with graph.as_default():\n",
        "\n",
        "  # Input data.\n",
        "  tf_train_dataset = tf.placeholder(\n",
        "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
        "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
        "  tf_valid_dataset = tf.constant(valid_dataset)\n",
        "  tf_test_dataset = tf.constant(test_dataset)\n",
        "  global_step = tf.Variable(0)\n",
        "  \n",
        "  # Variables.\n",
        "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
        "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
        "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
        "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
        "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
        "  size3 = ((image_size - patch_size + 1) // 2 - patch_size + 1) // 2\n",
        "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
        "      [size3 * size3 * depth, num_hidden], stddev=0.1))\n",
        "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
        "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
        "      [num_hidden, num_hidden], stddev=0.1))\n",
        "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
        "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
        "      [num_hidden, num_labels], stddev=0.1))\n",
        "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
        "  \n",
        "  # Model.\n",
        "  def model(data, keep_prob):\n",
        "    # C1 input 28 x 28\n",
        "    conv1 = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='VALID')\n",
        "    bias1 = tf.nn.relu(conv1 + layer1_biases)\n",
        "    # S2 input 24 x 24\n",
        "    pool2 = tf.nn.avg_pool(bias1, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
        "    # C3 input 12 x 12\n",
        "    conv3 = tf.nn.conv2d(pool2, layer2_weights, [1, 1, 1, 1], padding='VALID')\n",
        "    bias3 = tf.nn.relu(conv3 + layer2_biases)\n",
        "    # S4 input 8 x 8\n",
        "    pool4 = tf.nn.avg_pool(bias3, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
        "    # F5 input 4 x 4\n",
        "    shape = pool4.get_shape().as_list()\n",
        "    reshape = tf.reshape(pool4, [shape[0], shape[1] * shape[2] * shape[3]])\n",
        "    hidden5 = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
        "    # F6\n",
        "    drop5 = tf.nn.dropout(hidden5, keep_prob)\n",
        "    hidden6 = tf.nn.relu(tf.matmul(hidden5, layer4_weights) + layer4_biases)\n",
        "    drop6 = tf.nn.dropout(hidden6, keep_prob)\n",
        "    return tf.matmul(drop6, layer5_weights) + layer5_biases\n",
        "  \n",
        "  # Training computation.\n",
        "  logits = model(tf_train_dataset, drop_out)\n",
        "  loss = tf.reduce_mean(\n",
        "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
        "    \n",
        "  # Optimizer.\n",
        "  learning_rate = tf.train.exponential_decay(0.05, global_step, 1000, 0.85, staircase=True)\n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
        "  \n",
        "  # Predictions for the training, validation, and test data.\n",
        "  train_prediction = tf.nn.softmax(logits)\n",
        "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 1.0))\n",
        "  test_prediction = tf.nn.softmax(model(tf_test_dataset, 1.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CmcEgSa-kiBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5202
        },
        "outputId": "24acecce-7c22-4a91-876a-2cd4fcee40e1"
      },
      "cell_type": "code",
      "source": [
        "num_steps = 5001\n",
        "\n",
        "with tf.Session(graph=graph) as session:\n",
        "  tf.initialize_all_variables().run()\n",
        "  print('Initialized')\n",
        "  for step in range(num_steps):\n",
        "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
        "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
        "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
        "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
        "    _, l, predictions = session.run(\n",
        "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
        "    if (step % 50 == 0):\n",
        "      print('Minibatch loss at step %d: %f' % (step, l))\n",
        "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
        "      print('Validation accuracy: %.1f%%' % accuracy(\n",
        "        valid_prediction.eval(), valid_labels))\n",
        "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Minibatch loss at step 0: 2.612286\n",
            "Minibatch accuracy: 6.2%\n",
            "Validation accuracy: 10.0%\n",
            "Minibatch loss at step 50: 2.204365\n",
            "Minibatch accuracy: 25.0%\n",
            "Validation accuracy: 31.6%\n",
            "Minibatch loss at step 100: 1.203354\n",
            "Minibatch accuracy: 50.0%\n",
            "Validation accuracy: 44.5%\n",
            "Minibatch loss at step 150: 1.234263\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 59.1%\n",
            "Minibatch loss at step 200: 1.053270\n",
            "Minibatch accuracy: 50.0%\n",
            "Validation accuracy: 63.0%\n",
            "Minibatch loss at step 250: 1.091832\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 71.5%\n",
            "Minibatch loss at step 300: 1.487272\n",
            "Minibatch accuracy: 43.8%\n",
            "Validation accuracy: 71.3%\n",
            "Minibatch loss at step 350: 1.224683\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 75.7%\n",
            "Minibatch loss at step 400: 0.761053\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 74.2%\n",
            "Minibatch loss at step 450: 1.198610\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 76.2%\n",
            "Minibatch loss at step 500: 0.833724\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 77.0%\n",
            "Minibatch loss at step 550: 0.925274\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 77.4%\n",
            "Minibatch loss at step 600: 0.741166\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 77.8%\n",
            "Minibatch loss at step 650: 0.826507\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 77.8%\n",
            "Minibatch loss at step 700: 0.863075\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 78.0%\n",
            "Minibatch loss at step 750: 0.791851\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 78.5%\n",
            "Minibatch loss at step 800: 1.295205\n",
            "Minibatch accuracy: 56.2%\n",
            "Validation accuracy: 79.8%\n",
            "Minibatch loss at step 850: 0.686463\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 80.1%\n",
            "Minibatch loss at step 900: 1.034425\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 80.0%\n",
            "Minibatch loss at step 950: 0.915939\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 79.8%\n",
            "Minibatch loss at step 1000: 0.608615\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 80.3%\n",
            "Minibatch loss at step 1050: 0.377546\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 81.3%\n",
            "Minibatch loss at step 1100: 0.507404\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 81.5%\n",
            "Minibatch loss at step 1150: 0.621944\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 81.8%\n",
            "Minibatch loss at step 1200: 1.157026\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 81.4%\n",
            "Minibatch loss at step 1250: 0.933334\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 81.8%\n",
            "Minibatch loss at step 1300: 0.383494\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 81.9%\n",
            "Minibatch loss at step 1350: 0.497176\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 82.0%\n",
            "Minibatch loss at step 1400: 1.048450\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.4%\n",
            "Minibatch loss at step 1450: 0.746958\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.7%\n",
            "Minibatch loss at step 1500: 0.958932\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.9%\n",
            "Minibatch loss at step 1550: 0.528902\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.3%\n",
            "Minibatch loss at step 1600: 0.994624\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 82.5%\n",
            "Minibatch loss at step 1650: 0.188502\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 83.4%\n",
            "Minibatch loss at step 1700: 0.677978\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 82.5%\n",
            "Minibatch loss at step 1750: 0.579886\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.3%\n",
            "Minibatch loss at step 1800: 0.863837\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.2%\n",
            "Minibatch loss at step 1850: 0.523544\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 82.9%\n",
            "Minibatch loss at step 1900: 0.057875\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 83.4%\n",
            "Minibatch loss at step 1950: 0.166849\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 83.3%\n",
            "Minibatch loss at step 2000: 0.382441\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 83.7%\n",
            "Minibatch loss at step 2050: 0.470042\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 84.0%\n",
            "Minibatch loss at step 2100: 0.860743\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 83.9%\n",
            "Minibatch loss at step 2150: 1.117503\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 84.0%\n",
            "Minibatch loss at step 2200: 0.143962\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 83.9%\n",
            "Minibatch loss at step 2250: 0.391909\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.1%\n",
            "Minibatch loss at step 2300: 0.463298\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 84.3%\n",
            "Minibatch loss at step 2350: 0.347730\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.1%\n",
            "Minibatch loss at step 2400: 1.047814\n",
            "Minibatch accuracy: 56.2%\n",
            "Validation accuracy: 84.5%\n",
            "Minibatch loss at step 2450: 0.692317\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 84.4%\n",
            "Minibatch loss at step 2500: 0.694628\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 84.5%\n",
            "Minibatch loss at step 2550: 0.579887\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 2600: 0.217046\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 84.6%\n",
            "Minibatch loss at step 2650: 0.692321\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.6%\n",
            "Minibatch loss at step 2700: 0.414129\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.2%\n",
            "Minibatch loss at step 2750: 0.161879\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 84.4%\n",
            "Minibatch loss at step 2800: 0.303867\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.7%\n",
            "Minibatch loss at step 2850: 0.360646\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 2900: 0.261651\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.8%\n",
            "Minibatch loss at step 2950: 0.409423\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 3000: 0.751884\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 3050: 0.274851\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 84.5%\n",
            "Minibatch loss at step 3100: 0.968115\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 3150: 0.790012\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.0%\n",
            "Minibatch loss at step 3200: 0.708369\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 3250: 0.571757\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 84.9%\n",
            "Minibatch loss at step 3300: 1.013051\n",
            "Minibatch accuracy: 68.8%\n",
            "Validation accuracy: 84.9%\n",
            "Minibatch loss at step 3350: 0.390374\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.2%\n",
            "Minibatch loss at step 3400: 0.478364\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 3450: 0.418918\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.3%\n",
            "Minibatch loss at step 3500: 0.663053\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 3550: 0.161870\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 3600: 0.577038\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.4%\n",
            "Minibatch loss at step 3650: 0.555453\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 3700: 0.575897\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.1%\n",
            "Minibatch loss at step 3750: 1.073994\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 3800: 0.515863\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 3850: 0.494168\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.6%\n",
            "Minibatch loss at step 3900: 0.483273\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 3950: 0.610437\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 85.2%\n",
            "Minibatch loss at step 4000: 0.573254\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 85.7%\n",
            "Minibatch loss at step 4050: 0.361352\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4100: 0.395890\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4150: 0.445208\n",
            "Minibatch accuracy: 87.5%\n",
            "Validation accuracy: 86.2%\n",
            "Minibatch loss at step 4200: 0.435261\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4250: 0.038575\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4300: 0.044873\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4350: 0.250634\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4400: 0.111196\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 4450: 0.902102\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4500: 0.425320\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 4550: 0.806142\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.5%\n",
            "Minibatch loss at step 4600: 0.702086\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4650: 0.823213\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 85.8%\n",
            "Minibatch loss at step 4700: 0.475906\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4750: 0.260401\n",
            "Minibatch accuracy: 93.8%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4800: 0.381858\n",
            "Minibatch accuracy: 81.2%\n",
            "Validation accuracy: 86.1%\n",
            "Minibatch loss at step 4850: 0.656983\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 86.0%\n",
            "Minibatch loss at step 4900: 0.630954\n",
            "Minibatch accuracy: 75.0%\n",
            "Validation accuracy: 86.5%\n",
            "Minibatch loss at step 4950: 1.295163\n",
            "Minibatch accuracy: 62.5%\n",
            "Validation accuracy: 86.2%\n",
            "Minibatch loss at step 5000: 0.039320\n",
            "Minibatch accuracy: 100.0%\n",
            "Validation accuracy: 86.3%\n",
            "Test accuracy: 92.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6db_gs9NkiAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}